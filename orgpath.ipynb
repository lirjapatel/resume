{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:08.045880Z",
     "iopub.status.busy": "2025-02-03T17:55:08.045677Z",
     "iopub.status.idle": "2025-02-03T17:55:08.049261Z",
     "shell.execute_reply": "2025-02-03T17:55:08.048752Z"
    }
   },
   "outputs": [],
   "source": [
    "# result = resumes_collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:08.051128Z",
     "iopub.status.busy": "2025-02-03T17:55:08.050942Z",
     "iopub.status.idle": "2025-02-03T17:55:09.086493Z",
     "shell.execute_reply": "2025-02-03T17:55:09.085762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (1.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:09.088657Z",
     "iopub.status.busy": "2025-02-03T17:55:09.088441Z",
     "iopub.status.idle": "2025-02-03T17:55:09.096222Z",
     "shell.execute_reply": "2025-02-03T17:55:09.095668Z"
    }
   },
   "outputs": [],
   "source": [
    "# # API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from a .env file\n",
    "uri = os.environ.get('MONGODB_URI')\n",
    "api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:09.098051Z",
     "iopub.status.busy": "2025-02-03T17:55:09.097859Z",
     "iopub.status.idle": "2025-02-03T17:55:09.983005Z",
     "shell.execute_reply": "2025-02-03T17:55:09.982349Z"
    },
    "id": "75Ye16UW_ehX",
    "outputId": "b6e67e6d-68c7-4195-f0ec-9c363c91d5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (4.11)\r\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pymongo) (2.7.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymongo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:09.985449Z",
     "iopub.status.busy": "2025-02-03T17:55:09.985006Z",
     "iopub.status.idle": "2025-02-03T17:55:10.397351Z",
     "shell.execute_reply": "2025-02-03T17:55:10.396699Z"
    },
    "id": "-C9kUPdf_fbk"
   },
   "outputs": [],
   "source": [
    "import certifi\n",
    "import pymongo  #this is a library to allows us to work with mongodb from python\n",
    "from pymongo.mongo_client import MongoClient   #this is used to create a connection to a mongodb instance\n",
    "from pymongo.server_api import ServerApi    #is used to specify the version of mongodb server API to use when connecting\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from datetime import datetime, timezone\n",
    "from pymongo.errors import ConfigurationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:10.399836Z",
     "iopub.status.busy": "2025-02-03T17:55:10.399452Z",
     "iopub.status.idle": "2025-02-03T17:55:11.341568Z",
     "shell.execute_reply": "2025-02-03T17:55:11.340851Z"
    },
    "id": "-jdYfFpxEYXO",
    "outputId": "d737fede-73a9-4b8c-d61f-8a9421ea5190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting MongoDB Connection...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# #URI is (Uniform Resource Identifier)\n",
    "# # we used username , password , cluster address and connection options like (retryWrites=true, w=majority, appName=Cluster0)\n",
    "\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "# client = MongoClient(uri, server_api=ServerApi('1'), tlsCAFile=certifi.where()),\n",
    "# server_api=ServerApi('1'), tlsCAFile=certifi.where()\n",
    "\n",
    "\n",
    "# # Send a ping to confirm a successful connection and printing a success message or an error it it fails\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import certifi\n",
    "from pymongo.errors import ConfigurationError, ConnectionFailure\n",
    "import sys\n",
    "import os\n",
    "import pymongo\n",
    "import certifi\n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "import os\n",
    "import pymongo\n",
    "import certifi\n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "# Get MongoDB URI from environment variables\n",
    "uri = os.environ.get('MONGODB_URI')\n",
    "if not uri:\n",
    "    raise ValueError(\"MongoDB URI is not set in environment variables\")\n",
    "\n",
    "print(\"Attempting MongoDB Connection...\")\n",
    "\n",
    "client = MongoClient(\n",
    "    uri, \n",
    "    server_api=ServerApi('1'),  # Ensure this line has a comma at the end\n",
    "    tlsCAFile=certifi.where(),\n",
    "    connectTimeoutMS=30000,\n",
    "    socketTimeoutMS=30000\n",
    ")\n",
    "\n",
    "# Ping the deployment\n",
    "client.admin.command('ping')\n",
    "print(\"Successfully connected to MongoDB!\")\n",
    "\n",
    "\n",
    "\n",
    "# # Explicitly load environment variables\n",
    "# # load_dotenv()\n",
    "\n",
    "# # # Print environment details\n",
    "# # print(\"Python Version:\", sys.version)\n",
    "# # print(\"Current Working Directory:\", os.getcwd())\n",
    "# # print(\"Environment Variables:\")\n",
    "# # print(\"MONGODB_URI:\", os.getenv('MONGODB_URI'))\n",
    "\n",
    "# try:\n",
    "#     import pymongo\n",
    "\n",
    "#     # Detailed connection attempt\n",
    "#     uri = os.getenv('MONGODB_URI')\n",
    "#     if not uri:\n",
    "#         raise ValueError(\"MongoDB URI is not set in environment variables\")\n",
    "\n",
    "#     print(\"Attempting MongoDB Connection...\")\n",
    "#     client = MongoClient(\n",
    "#         uri, \n",
    "#         server_api=ServerApi('1'), \n",
    "#         tlsCAFile=certifi.where(),\n",
    "#         connectTimeoutMS=30000,\n",
    "#         socketTimeoutMS=30000\n",
    "#     )\n",
    "\n",
    "#     # Ping the deployment\n",
    "#     client.admin.command('ping')\n",
    "#     print(\"Successfully connected to MongoDB!\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Full Error Details:\")\n",
    "#     print(f\"Error Type: {type(e).__name__}\")\n",
    "#     print(f\"Error Message: {str(e)}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0MdDcrrLjgU"
   },
   "source": [
    "\n",
    "NEW CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:11.343758Z",
     "iopub.status.busy": "2025-02-03T17:55:11.343557Z",
     "iopub.status.idle": "2025-02-03T17:55:21.419841Z",
     "shell.execute_reply": "2025-02-03T17:55:21.419080Z"
    },
    "id": "eAJRdz82nB5v",
    "outputId": "52e7fde3-4f63-49e5-d3c8-ca6494968d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (4.11)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: openai in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (1.61.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\r\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting python-docx\r\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\r\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pymongo) (2.7.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.8.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (0.8.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (2.10.6)\r\n",
      "Requirement already satisfied: sniffio in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.12.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml>=3.1.0 (from python-docx)\r\n",
      "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from langchain_community) (6.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\r\n",
      "  Using cached SQLAlchemy-2.0.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\r\n",
      "  Using cached aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\r\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\r\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain<0.4.0,>=0.3.16 (from langchain_community)\r\n",
      "  Using cached langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Collecting langchain-core<0.4.0,>=0.3.32 (from langchain_community)\r\n",
      "  Using cached langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langsmith<0.4,>=0.1.125 (from langchain_community)\r\n",
      "  Using cached langsmith-0.3.4-py3-none-any.whl.metadata (14 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2,>=1.22.4 (from langchain_community)\r\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\r\n",
      "  Using cached pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from langchain_community) (2.32.3)\r\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\r\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\r\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\r\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain<0.4.0,>=0.3.16->langchain_community)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.32->langchain_community)\r\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (24.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain_community)\r\n",
      "  Using cached orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\r\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain_community)\r\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain_community)\r\n",
      "  Using cached zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\r\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain_community) (3.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\r\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\r\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\r\n",
      "Using cached langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\r\n",
      "Using cached aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\r\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\r\n",
      "Using cached langchain-0.3.17-py3-none-any.whl (1.0 MB)\r\n",
      "Using cached langchain_core-0.3.33-py3-none-any.whl (412 kB)\r\n",
      "Using cached langsmith-0.3.4-py3-none-any.whl (333 kB)\r\n",
      "Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\r\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\r\n",
      "Using cached SQLAlchemy-2.0.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\r\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\r\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\r\n",
      "Using cached greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\r\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\r\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\r\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\r\n",
      "Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\r\n",
      "Using cached orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\r\n",
      "Using cached propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\r\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\n",
      "Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\r\n",
      "Using cached zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: zstandard, tenacity, PyPDF2, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, lxml, jsonpatch, httpx-sse, greenlet, frozenlist, async-timeout, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, python-docx, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain_community\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.2.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling numpy-2.2.2:\r\n",
      "      Successfully uninstalled numpy-2.2.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed PyPDF2-3.0.1 SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.17 langchain-core-0.3.33 langchain-text-splitters-0.3.5 langchain_community-0.3.16 langsmith-0.3.4 lxml-5.3.0 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.15 propcache-0.2.1 pydantic-settings-2.7.1 python-docx-1.1.2 requests-toolbelt-1.0.0 tenacity-9.0.0 typing-inspect-0.9.0 yarl-1.18.3 zstandard-0.23.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymongo python-dotenv openai PyPDF2 python-docx langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:21.422245Z",
     "iopub.status.busy": "2025-02-03T17:55:21.421828Z",
     "iopub.status.idle": "2025-02-03T17:55:23.280275Z",
     "shell.execute_reply": "2025-02-03T17:55:23.279574Z"
    },
    "id": "m0T0gq1nKPO5",
    "outputId": "17549376-15a4-43e1-fd70-c67e18526522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (3.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (1.1.2)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from python-docx) (5.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from python-docx) (4.12.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2 \n",
    "%pip install python-docx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:23.282542Z",
     "iopub.status.busy": "2025-02-03T17:55:23.282119Z",
     "iopub.status.idle": "2025-02-03T17:55:24.325673Z",
     "shell.execute_reply": "2025-02-03T17:55:24.324959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (1.61.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.8.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (0.8.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (2.10.6)\r\n",
      "Requirement already satisfied: sniffio in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\r\n",
      "Requirement already satisfied: certifi in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7mPU241m5NE"
   },
   "source": [
    "\n",
    "## **Resume Extraction and Processing System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:24.328055Z",
     "iopub.status.busy": "2025-02-03T17:55:24.327629Z",
     "iopub.status.idle": "2025-02-03T17:55:24.750131Z",
     "shell.execute_reply": "2025-02-03T17:55:24.749537Z"
    },
    "id": "Neyqs2toK66I",
    "outputId": "3d891998-b504-4da1-f39d-b066fe78d3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the latest resume in the database.\n",
      "Processing: Resume-1.pdf\n",
      "Extracted text from PDF (Resume Text): LIRJA PATEL  \n",
      "Linkedin  | patellirja@gmail.com  | +1- 4168217130  | GitHub  | Brampton , Ontario, Canada  \n",
      "EDUCATION  \n",
      " \n",
      "Sheridan College Institute of Technology and Advanced Learning  | Brampton, Canada               Sep’2 3 – Dec’24 \n",
      "Computer Programming                  \n",
      "Coursework:  Python  Programming , Project Oriented Programming Java, Enterprise Java Development, Data Structures and Algorithm Development  \n",
      "C, .NET Technologies using  C#, Web Development, Computer Math Fundamentals, Introduction to Data Communications and Ne tworking, Cloud Enabled \n",
      "Networks, Database Design and Implementation, Linux Operating system, Web Programming, AI and Machine Learning, Computer & Ne twork Security, \n",
      "Database Management, Fundamentals of Software Design, Mobile Web -based Applications, Hybrid  Mobile Application Development, IT Project \n",
      "Management using PMP, Systems Development Methodologies , The Art of Technical Commu nication   \n",
      " \n",
      "WORK EXPERIENCE  \n",
      " \n",
      "AI/ML Data Engineer | Org Path Inc.                                                                                                                                    Oct’24 – Dec’24 \n",
      "• Technologies Used:  Python, JavaScript, MongoD B, OpenAI API , Langchain  \n",
      "• Developed a system where users can upl oad their resumes, utilizing OpenAI’s API  using Langchain  to analyze and evaluate resumes efficiently  \n",
      "• Implemented API -driven processes for real -time feedback and quantitative assessment of resumes  \n",
      "• Leveraged MongoDB to manage and store user data, including  resume details, analysis results, and feedback history efficiently  \n",
      " \n",
      "Junior Data Analyst | Kiluam Software Inc.                                                                                                                          June ’24 – Sep’24  \n",
      "• Technologies Used:  Python, SQL , Pandas. Tableau, Matplotlib, Seaborn  \n",
      "• Designed and implemented a comprehensive data pi peline to analyze customer purchase behaviour , integrating multiple data sources and \n",
      "utilizing Python for data cleaning and processing  \n",
      "• Developed an SQL database to store processed data efficiently, enabling quick retrieval and analysis of customer informat ion and purchase \n",
      "patterns  \n",
      "• Created automated dashboards using Python libraries (Matplotlib, Seaborn) and Tableau to visualize sales trends, key performa nce metrics, and \n",
      "churn patterns, facilitating data  driven decision -making for marketing strategies  \n",
      " \n",
      "PROJECTS  \n",
      " \n",
      "Restaurant Tips Prediction  (Website )  \n",
      "• Technologies Used:  Python, Machine Learning, Pandas, Matplotlib , Scikit -Learn  \n",
      "• Cleaned and visualized key dataset features to identify tipping patterns and influential factors, such as total bill, gender, and group size, using \n",
      "Python libraries  \n",
      "• Evaluated model performance using metrics like mean absolute error, root mean squared error, and R -squared, providing actionable insights for \n",
      "resta urant customer  behaviour   \n",
      "Tic Tac Toe Game  (Website )  \n",
      "• Technologies Used:  HTML, CSS, JavaScript  \n",
      "• The p layer competes against the computer, utilizing algorithms to simulate intelligent gameplay  \n",
      "• Designed game logic to handle win/loss conditions, game reset, and user inputs, ensuring a smooth gameplay experience for both human and \n",
      "computer players  \n",
      "• Created an interactive user interface to display the game board and update moves  in real-time \n",
      "College Registrar's Office Database System  (GitHub )               \n",
      "• Technologies Used:  SQL,  \n",
      "• Created a robust SQL database for managing student records, courses, and faculty assignments  \n",
      "• Applied 3NF normalization to improve data integrity and reduce redundancy  \n",
      "• Developed SQL scripts for table creation and data queries, and designed ER diagrams for clear data  relationships  \n",
      "Form Submission with Angular  (GitHub ) \n",
      "• Technologies Used:  Angular  \n",
      "• Implemented a responsive mobile -friendly Angular app using Material Design, adhering to modular architecture principles  \n",
      "• Successfully fetched and displayed data from external JSON  files in a reactive form, ensuring dynamic updates based on user input  \n",
      "• Deployed the Angular application on cPanel  \n",
      " \n",
      " Flipkart Clone (GitHub ) \n",
      "• Technologies Used:  HTML, CSS, JavaScript  \n",
      "• Implemented a responsive mobile -friendly Angular app using Material Design, adhering to modular architecture principles  \n",
      "• Successfully fetched and displayed data from external JSON files in a reactive form, ensuring dynamic updates bas ed on user input  \n",
      "• Deployed the Angular application on cPanel  \n",
      "Website using Amazon S3 and (CORS)  policies   \n",
      "• Technologies Used:  AWS   \n",
      "• Set up and configured static websites on Amazon S3 buckets, managing policies for public access, bucket policies, and CORS to  enable \n",
      "resource sharing across buckets  \n",
      "• Configured CORS policies for secure resource sharing between S3 buckets, ensuring cross -bucket functionality in a web environment  \n",
      "Network Configuration and Security Management in AWS   \n",
      "• Technologies Used:  AWS  \n",
      "• Set up and labelled  multiple subnets, placed VMs, and configured network architecture  \n",
      "• Installed Docker on VMs and deployed Nginx containers  \n",
      "• Configured NACLs and security groups for access control and traffic  management  \n",
      " \n",
      "SKILLS  \n",
      " \n",
      "Languages: Python, C, Linux , JavaScript , HTML , CSS  \n",
      "Libraries: Pandas, NumPy, Matplotlib, Scikit -learn , Langchain  \n",
      "Framework:  Angular, Node.js  \n",
      "Database : SQL , MongoDB  \n",
      "Cloud Services : AWS  \n",
      " \n",
      "EXTRACURRICULAR  \n",
      " \n",
      "Technical Head | Coding Syndicate | Sheridan College     June’22 – July‘23  \n",
      "• Conducting  Python  workshop s for juniors and peers  \n",
      "• Organi zing a Coding contest at our college  \n",
      "Tutor  | EEC  | Gandhinagar , Gujarat    June’22 – July‘23  \n",
      "• Teaching English to students for the IELTS examination and solving their doubts  \n",
      " \n",
      "CERTIFICATIONS  \n",
      " \n",
      "• IBM Data Analyst Professional Certificate from IBM  through Coursera  \n",
      "• Network Defen ce from Cisco Networking Academy  \n",
      "• Ethical Hacker from Cisco Networking Academy  ...\n",
      "------------------------\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "# These lines access the 'ResumeDatabase' and its 'Resume' collection\n",
    "db = client['ResumeDatabase']\n",
    "#\n",
    "resumes_collection = db['Resume']\n",
    "#Retrieves a specific collection named 'Resume' from the 'ResumeDatabase'.\n",
    "\n",
    "\n",
    "# In mongodb atlas, project\n",
    "# cluster\n",
    "# configuratuion\n",
    "\n",
    "# Fetch only the latest document from 'Resume' collection with sorted by \"uploadedAt\" field in decending order(-1)\n",
    "latest_resume = resumes_collection.find_one(sort=[('uploadedAt', -1)])\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "if latest_resume:  # this checks if a resume was found in the database\n",
    "    print(\"Found the latest resume in the database.\")\n",
    "\n",
    "    filename = latest_resume.get('filename', 'Unknown')\n",
    "    #provides file name if not displays \"UNKNOWN\"\n",
    "    content = latest_resume.get('content')\n",
    "    #extract the content of document\n",
    "    content_type = latest_resume.get('contentType')\n",
    "    #content type give info about nature and format of document  like PDF\"application/pdf\n",
    "#or .doc and .docx\n",
    "\n",
    "    print(f\"Processing: {filename}\") #This prints the filename of the resume being processed.\n",
    "\n",
    "\n",
    "    if content_type == 'application/pdf':\n",
    "      #this check if a document is a pdf\n",
    "        # Process PDF\n",
    "        try:\n",
    "            import io\n",
    "            from PyPDF2 import PdfReader\n",
    "\n",
    "            pdf_file = io.BytesIO(content) #These lines create a file-like object from the content and initialize a PDF reader.\n",
    "            pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "\n",
    "             #This extracts text from each page of the PDF and concatenates it.\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "            print(f\"Extracted text from PDF (Resume Text): {text[:]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF {filename}: {str(e)}\")\n",
    "\n",
    "    elif content_type in ['application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document']:\n",
    "        # This checks if the document is a Word file (.doc or .docx).\n",
    "\n",
    "        try:\n",
    "            import io\n",
    "            from docx import Document\n",
    "\n",
    "            #These lines create a file-like object from the content and load it as a Word document.\n",
    "            doc_file = io.BytesIO(content)\n",
    "            document = Document(doc_file)\n",
    "\n",
    "            #This extracts text from each paragraph in the Word document and joins them with newlines.\n",
    "            text = \"\\n\".join([para.text for para in document.paragraphs])\n",
    "\n",
    "            print(f\"Extracted text from Word document (Resume Text): {text[:]}...\") # this prints the extracted text frm the word document\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing Word document {filename}: {str(e)}\") #this handles cases where the file type is neither PDF nor word\n",
    "\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {content_type}\")\n",
    "\n",
    "    print(\"------------------------\")\n",
    "\n",
    "else:\n",
    "    print(\"No resumes found in the database.\")\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-3mbT6fvs9r"
   },
   "source": [
    "# **Providing the resume to openai api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:24.752272Z",
     "iopub.status.busy": "2025-02-03T17:55:24.751880Z",
     "iopub.status.idle": "2025-02-03T17:55:25.689425Z",
     "shell.execute_reply": "2025-02-03T17:55:25.688689Z"
    },
    "id": "pxdEn1CIWcmK",
    "outputId": "f3ee1df5-cf31-47d3-e423-d8a9d8849603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (1.61.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.8.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (0.8.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (2.10.6)\r\n",
      "Requirement already satisfied: sniffio in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\r\n",
      "Requirement already satisfied: certifi in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:25.692129Z",
     "iopub.status.busy": "2025-02-03T17:55:25.691606Z",
     "iopub.status.idle": "2025-02-03T17:55:36.394658Z",
     "shell.execute_reply": "2025-02-03T17:55:36.394034Z"
    },
    "id": "4dLhEkLRXcBC",
    "outputId": "c6843226-7883-4df9-f678-7c20fff0d0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume analysis completed and stored in database\n",
      "\n",
      "Analysis Result:\n",
      "==================================================\n",
      "Lirja Patel is a skilled Computer Programming graduate from Sheridan College with a strong foundation in **Python, Java, C#, SQL, and web development**. With experience as an AI/ML Data Engineer and Junior Data Analyst, she has utilized **Python, JavaScript, MongoDB, SQL, and Tableau** to develop systems for resume analysis and customer behavior insights. Lirja's projects showcase her proficiency in **machine learning, data visualization, and database management**. Her technical skills include **Pandas, NumPy, Matplotlib, Scikit-learn, Angular, Node.js, SQL, MongoDB, AWS**, and more. Additionally, her leadership roles as a Technical Head and Tutor demonstrate her **communication and teaching abilities**. Lirja holds certifications in **IBM Data Analyst Professional Certificate** and **Network Defense and Ethical Hacker from Cisco Networking Academy**, highlighting her commitment to continuous learning and professional development.\n",
      "\n",
      "Sections to Highlight:\n",
      "==================================================\n",
      "Text: Sep’23 – Dec’24\n",
      "Reason: Date format inconsistency\n",
      "Suggestion: Change the date format to 'Sep 2023 - Dec 2024' for consistency.\n",
      "------------------------------\n",
      "Text: • Technologies Used: Python, JavaScript, MongoDB, OpenAI API, Langchain\n",
      "Reason: Lack of consistency in listing technologies\n",
      "Suggestion: Consistently list technologies with or without spaces after commas, e.g., 'Python, JavaScript, MongoDB, OpenAI API, Langchain'.\n",
      "------------------------------\n",
      "Text: • Developed a system where users can upload their resumes, utilizing OpenAI’s API using Langchain to analyze and evaluate resumes efficiently\n",
      "Reason: Repetitive use of 'resumes'\n",
      "Suggestion: Avoid repetition by rephrasing as '...to analyze and evaluate them efficiently'.\n",
      "------------------------------\n",
      "Text: • Created automated dashboards using Python libraries (Matplotlib, Seaborn) and Tableau to visualize sales trends, key performance metrics, and churn patterns, facilitating data-driven decision-making for marketing strategies\n",
      "Reason: Long sentence with multiple components\n",
      "Suggestion: Break down the sentence into shorter, clearer points for better readability and understanding.\n",
      "------------------------------\n",
      "Text: • Evaluated model performance using metrics like mean absolute error, root mean squared error, and R-squared, providing actionable insights for restaurant customer behaviour\n",
      "Reason: Lack of parallel structure in listing metrics\n",
      "Suggestion: Maintain parallel structure when listing metrics, e.g., 'mean absolute error, root mean squared error, and R-squared'.\n",
      "------------------------------\n",
      "Text: • The player competes against the computer, utilizing algorithms to simulate intelligent gameplay\n",
      "Reason: Passive voice usage\n",
      "Suggestion: Use active voice for clearer and more engaging descriptions, e.g., 'The player competes against the computer using algorithms to simulate intelligent gameplay'.\n",
      "------------------------------\n",
      "Text: • Created a robust SQL database for managing student records, courses, and faculty assignments\n",
      "Reason: Lack of specific details\n",
      "Suggestion: Provide more specific details on the database structure, relationships, or challenges faced to enhance the description.\n",
      "------------------------------\n",
      "Text: • Successfully fetched and displayed data from external JSON files in a reactive form, ensuring dynamic updates based on user input\n",
      "Reason: Repetitive content in project descriptions\n",
      "Suggestion: Avoid repeating similar achievements in project descriptions to maintain uniqueness and relevance.\n",
      "------------------------------\n",
      "Text: • Set up and configured static websites on Amazon S3 buckets, managing policies for public access, bucket policies, and CORS to enable resource sharing across buckets\n",
      "Reason: Long and complex sentence\n",
      "Suggestion: Break down the sentence into simpler, more digestible points for better comprehension.\n",
      "------------------------------\n",
      "Text: • Set up and labelled multiple subnets, placed VMs, and configured network architecture\n",
      "Reason: Lack of details on the network setup\n",
      "Suggestion: Include specific details on the network setup, configurations, and any challenges faced during the process.\n",
      "------------------------------\n",
      "Text: • Conducting Python workshops for juniors and peers\n",
      "Reason: Inconsistent tense usage\n",
      "Suggestion: Maintain consistent tense throughout the extracurricular activities section, e.g., 'Conducted Python workshops for juniors and peers'.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#The OpenAI class is used to interact with OpenAI API\n",
    "import json\n",
    "#The datetime class is used for timestamping\n",
    "from datetime import datetime\n",
    "\n",
    "#This line takes two parameters:the resume text and an API key for OpenAI.\n",
    "def analyze_resume_with_openai(text, api_key):\n",
    "  #This creates an instance of the OpenAI client using the provided API key.\n",
    "  client = OpenAI(api_key=api_key)\n",
    "\n",
    "#This block sends a request to the OpenAI API to analyze the resume using GTP-3.5 turbo\n",
    "  try:\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                # \"role\": \"system\",\n",
    "                # \"content\": '''You are a resume analyzer. Analyze the following resume and provide key insights, improvements and recomendations. Do not include any concluding statements like 'Overall,' 'In conclusion,' or\n",
    "                #     'By implementing these improvements'. Focus only on presenting insights, improvements, and specific recommendations.'''\n",
    "        \n",
    "                \"role\": \"system\", \n",
    "                \"content\": '''You are a resume analyzer. Analyze the following resume and provide a summary in one paragraph under 500 words. The summary should highlight the individual's qualifications, experience, and key strengths, and explicitly make all skills the bold( write them inside **). Give it without any title'''\n",
    "                # \"content\": '''You are a resume analyzer. Analyze the following resume and provide Summary under 500 words in one paragraph also make the skills bold.'''\n",
    "\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        # this controls the randomness of the model output , higher temperature means increase creativity and variability\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "      # this returns the analysis result or an error message if an exception occurs\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "  except Exception as e:\n",
    "      return f\"Error analyzing resume: {str(e)}\"\n",
    "\n",
    "\n",
    "# NEW Highlight code\n",
    "def get_highlight_sections(analysis_text, api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a resume improvement expert. Analyze the resume sections that need improvement and provide specific suggestions for enhancement. Your response MUST be a valid JSON string in this format:\n",
    "{\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"text\": \"exact texts from resume that needs improvement\",\n",
    "            \"reason\": \"specific reason why this needs improvement\",\n",
    "            \"suggestion\": \"detailed suggestion for how to rewrite this section\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Do not include anything outside of the JSON structure.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Identify sections needing improvement and provide specific suggestions for enhancement: {analysis_text}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            highlights = json.loads(content)\n",
    "            if not isinstance(highlights, dict) or 'sections' not in highlights:\n",
    "                highlights = {\"sections\": []}\n",
    "            return highlights\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error parsing JSON response\")\n",
    "            return {\"sections\": []}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_highlight_sections: {str(e)}\")\n",
    "        return {\"sections\": []}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# commented out bcz we used this method earlier\n",
    "# # Connect to MongoDB and fetch resume\n",
    "# db = client['ResumeDatabase']\n",
    "# resumes_collection = db['Resume']\n",
    "\n",
    "# # Fetch latest resume\n",
    "# latest_resume = resumes_collection.find_one(sort=[('uploadedAt', -1)])\n",
    "\n",
    "if latest_resume:# this line checks if the resume was found in the database\n",
    "  content = latest_resume.get('content')\n",
    "  #these lines extract the content and content type of the resume from the databse document\n",
    "  content_type = latest_resume.get('contentType')\n",
    "\n",
    "  # Extract text based on file type\n",
    "  #This block handles PDF files. It uses PyPDF2 to read the PDF content and extract text from each page.\n",
    "  text = \"\"\n",
    "  if content_type == 'application/pdf':\n",
    "      try:\n",
    "          import io\n",
    "          from PyPDF2 import PdfReader\n",
    "\n",
    "          pdf_file = io.BytesIO(content)\n",
    "          pdf_reader = PdfReader(pdf_file)\n",
    "          for page in pdf_reader.pages:\n",
    "              text += page.extract_text()\n",
    "      except Exception as e:\n",
    "          print(f\"Error processing PDF: {str(e)}\")\n",
    "\n",
    "#This block handles Word documents (.doc and .docx). It uses the python-docx library to read the document and extract text from each paragraph.\n",
    "  elif content_type in ['application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document']:\n",
    "      try:\n",
    "          import io\n",
    "          from docx import Document\n",
    "\n",
    "          doc_file = io.BytesIO(content)\n",
    "          document = Document(doc_file)\n",
    "          text = \"\\n\".join([para.text for para in document.paragraphs])\n",
    "      except Exception as e:\n",
    "          print(f\"Error processing Word document: {str(e)}\")\n",
    "\n",
    "  if text:# if text was successfully extracted\n",
    "      # Send to OpenAI for analysis\n",
    "      analysis = analyze_resume_with_openai(text, api_key)\n",
    "      highlights = get_highlight_sections(text, api_key)\n",
    "\n",
    "\n",
    "      # Store the analysis back in MongoDB\n",
    "      #By storing resume in database it can be accessed later without re-analyze the resume, this is cheap option also bcz user does not have to pay extra for analyzed the resume as it is stored in the database\n",
    "      # this updates the mongodb document with analysis result and current timestamp\n",
    "      resumes_collection.update_one(\n",
    "          {'_id': latest_resume['_id']},\n",
    "          {\n",
    "              '$set': {\n",
    "                  'analysis': analysis,\n",
    "                  'highlights': highlights,\n",
    "                  'analyzed_at': datetime.utcnow()\n",
    "              }\n",
    "          }\n",
    "      )\n",
    "\n",
    "        #this lines print status messages based on the output of the process\n",
    "      print(\"Resume analysis completed and stored in database\")\n",
    "  else:\n",
    "      print(\"No text could be extracted from the resume\")\n",
    "else:\n",
    "  print(\"No resume found in database\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(\"\\nAnalysis Result:\")\n",
    "print(\"=\" * 50)\n",
    "print(analysis)\n",
    "# Modify the verification print section\n",
    "print(\"\\nSections to Highlight:\")\n",
    "print(\"=\" * 50)\n",
    "if isinstance(highlights, dict) and 'sections' in highlights:\n",
    "    for section in highlights['sections']:\n",
    "        print(f\"Text: {section['text']}\")\n",
    "        print(f\"Reason: {section['reason']}\")\n",
    "        print(f\"Suggestion: {section['suggestion']}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:36.396833Z",
     "iopub.status.busy": "2025-02-03T17:55:36.396456Z",
     "iopub.status.idle": "2025-02-03T17:55:36.400578Z",
     "shell.execute_reply": "2025-02-03T17:55:36.399912Z"
    },
    "id": "EnJDBsz8uoee",
    "outputId": "8cad201b-ce5c-4b53-b5ab-e691a15585f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "API Analysis Result:\n",
      "==================================================\n",
      "Lirja Patel is a skilled Computer Programming graduate from Sheridan College with a strong foundation in **Python, Java, C#, SQL, and web development**. With experience as an AI/ML Data Engineer and Junior Data Analyst, she has utilized **Python, JavaScript, MongoDB, SQL, and Tableau** to develop systems for resume analysis and customer behavior insights. Lirja's projects showcase her proficiency in **machine learning, data visualization, and database management**. Her technical skills include **Pandas, NumPy, Matplotlib, Scikit-learn, Angular, Node.js, SQL, MongoDB, AWS**, and more. Additionally, her leadership roles as a Technical Head and Tutor demonstrate her **communication and teaching abilities**. Lirja holds certifications in **IBM Data Analyst Professional Certificate** and **Network Defense and Ethical Hacker from Cisco Networking Academy**, highlighting her commitment to continuous learning and professional development.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # Print the analysis result\n",
    "  #This code block is responsible for printing the results of the resume analysis\n",
    "  print(\"\\nAPI Analysis Result:\")\n",
    "  print(\"=\" * 50)\n",
    "  print(analysis)\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "#any errors that occurred during the process\n",
    "except Exception as e:\n",
    "  error_message = f\"Error analyzing resume: {str(e)}\"\n",
    "  print(\"\\nError:\")\n",
    "  print(\"=\" * 50)\n",
    "  print(error_message)\n",
    "  print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kkm-JXSN5Dv3"
   },
   "source": [
    "# **Scores based on orgpath pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:36.402621Z",
     "iopub.status.busy": "2025-02-03T17:55:36.402243Z",
     "iopub.status.idle": "2025-02-03T17:55:37.557058Z",
     "shell.execute_reply": "2025-02-03T17:55:37.556386Z"
    },
    "id": "CxPhWfSVHwBk",
    "outputId": "7889fe1c-40c9-4405-db8a-ee3d1608523f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw API response: ```json\n",
      "{\n",
      "    \"OVERALL SCORE\": 85,\n",
      "    \"FORMATTING & PRESENTATION\": 90,\n",
      "    \"SOFT-SKILLS INFORMATION\": 80,\n",
      "    \"RELEVANT EXPERIENCE\": 85,\n",
      "    \"ACHIEVEMENT & IMPACT\": 90\n",
      "}\n",
      "```\n",
      "Resume analysis and assessment scores completed and stored in database\n",
      "\n",
      "API Analysis Result:\n",
      "==================================================\n",
      "Lirja Patel is a skilled Computer Programming graduate from Sheridan College with a strong foundation in **Python, Java, C#, SQL, and web development**. With experience as an AI/ML Data Engineer and Junior Data Analyst, she has utilized **Python, JavaScript, MongoDB, SQL, and Tableau** to develop systems for resume analysis and customer behavior insights. Lirja's projects showcase her proficiency in **machine learning, data visualization, and database management**. Her technical skills include **Pandas, NumPy, Matplotlib, Scikit-learn, Angular, Node.js, SQL, MongoDB, AWS**, and more. Additionally, her leadership roles as a Technical Head and Tutor demonstrate her **communication and teaching abilities**. Lirja holds certifications in **IBM Data Analyst Professional Certificate** and **Network Defense and Ethical Hacker from Cisco Networking Academy**, highlighting her commitment to continuous learning and professional development.\n",
      "\n",
      "Assessment Scores:\n",
      "==================================================\n",
      "OVERALL SCORE: 85\n",
      "FORMATTING & PRESENTATION: 90\n",
      "SOFT-SKILLS INFORMATION: 80\n",
      "RELEVANT EXPERIENCE: 85\n",
      "ACHIEVEMENT & IMPACT: 90\n",
      "==================================================\n",
      "\n",
      "Score Interpretation:\n",
      "==================================================\n",
      "OVERALL SCORE: Excellent for entry-level\n",
      "FORMATTING & PRESENTATION: Excellent for entry-level\n",
      "SOFT-SKILLS INFORMATION: Excellent for entry-level\n",
      "RELEVANT EXPERIENCE: Excellent for entry-level\n",
      "ACHIEVEMENT & IMPACT: Excellent for entry-level\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Updated criteria based on the OrgInsights Assessment guide\n",
    "    # \"Overall Score\",\n",
    "    # \"Develops Talent\",\n",
    "    # \"Builds Relationships\",\n",
    "    # \"Communicates Effectively\",\n",
    "    # \"Drives Results\",\n",
    "    # \"Demonstrates Adaptability\",\n",
    "    # \"Shows Business Acumen\",\n",
    "    # \"Thinks Strategically\",\n",
    "    # \"Leads Change\",\n",
    "    # \"Demonstrates Integrity\"\n",
    "criteria = [\n",
    "    \"OVERALL SCORE\",\n",
    "    \"FORMATTING & PRESENTATION\",\n",
    "    \"SOFT-SKILLS INFORMATION\",\n",
    "    \"RELEVANT EXPERIENCE\",\n",
    "    \"ACHIEVEMENT & IMPACT\"\n",
    "\n",
    "]\n",
    "def generate_assessment_scores(analysis_text, criteria):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an AI assistant that generates numerical scores for resume criteria based on the OrgInsights Assessment guide. Output should be a JSON object with scores between 0 and 100 for each criterion. \"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Based on this resume text, generate scores for the following criteria: {', '.join(criteria)}. Analysis: {analysis_text}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        print(\"Raw API response:\", content)  # Print raw response for debugging\n",
    "        raw_response = content.strip()\n",
    "        if raw_response.startswith(\"```json\") and raw_response.endswith(\"```\"):\n",
    "            content = raw_response[7:-3].strip()\n",
    "\n",
    "        \n",
    "\n",
    "        if content.startswith(\"``````\"):\n",
    "            content = content[3:-3]\n",
    "        if content.startswith(\"json\"):\n",
    "            content = content[4:]\n",
    "        content = content.strip()\n",
    "\n",
    "        scores = json.loads(content)\n",
    "        return scores\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON Decode Error: {str(e)}\")\n",
    "        print(\"Raw content causing error:\", content)\n",
    "\n",
    "        return f\"Error parsing JSON: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        print(f\"General Error: {str(e)}\")\n",
    "        return f\"Error generating assessment scores: {str(e)}\"\n",
    "\n",
    "# Assuming you have the analysis text stored in a variable called 'analysis'\n",
    "scores = generate_assessment_scores(analysis, criteria)\n",
    "\n",
    "if isinstance(scores, dict):\n",
    "    # Store the analysis and scores back in MongoDB\n",
    "    resumes_collection.update_one(\n",
    "        {'_id': latest_resume['_id']},\n",
    "        {\n",
    "            '$set': {\n",
    "                'assessment_scores': scores,\n",
    "                'scored_at': datetime.utcnow()\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Resume analysis and assessment scores completed and stored in database\")\n",
    "\n",
    "    print(\"\\nAPI Analysis Result:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(analysis)\n",
    "    print(\"\\nAssessment Scores:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for criterion, score in scores.items():\n",
    "        print(f\"{criterion}: {score}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Add interpretation of scores based on the guide\n",
    "    print(\"\\nScore Interpretation:\")\n",
    "    print(\"=\" * 50)\n",
    "    experience_level = \"Entry-level\"  # You may need to determine this based on the resume content\n",
    "    for criterion, score in scores.items():\n",
    "        if criterion != \"Overall Score\":\n",
    "            if experience_level == \"Entry-level\":\n",
    "                if score >= 70:\n",
    "                    print(f\"{criterion}: Excellent for entry-level\")\n",
    "                elif score >= 50:\n",
    "                    print(f\"{criterion}: Good for entry-level\")\n",
    "                else:\n",
    "                    print(f\"{criterion}: Needs improvement\")\n",
    "            else:\n",
    "                if score >= 80:\n",
    "                    print(f\"{criterion}: Meets senior-level expectations\")\n",
    "                elif score >= 60:\n",
    "                    print(f\"{criterion}: Acceptable, but room for growth\")\n",
    "                else:\n",
    "                    print(f\"{criterion}: Below expectations for experienced professionals\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "else:\n",
    "    print(\"Error in generating scores:\")\n",
    "    print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elevator Pitch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:37.559236Z",
     "iopub.status.busy": "2025-02-03T17:55:37.558917Z",
     "iopub.status.idle": "2025-02-03T17:55:39.155590Z",
     "shell.execute_reply": "2025-02-03T17:55:39.154880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevator pitch generated and stored successfully:\n",
      "Hi, I'm Lirja Patel, a Computer Programming graduate from Sheridan College with a strong foundation in Python, Java, and AI/ML. As an AI/ML Data Engineer at Org Path Inc., I developed a resume analysis system using OpenAI API and MongoDB for efficient data management. At Kiluam Software Inc., I crafted data pipelines and automated dashboards using Python and SQL for data-driven marketing decisions. My projects showcase skills in Machine Learning, web development, and database management. With certifications in Data Analysis and Network Defense, I bring a versatile skill set in Python, SQL, AWS, and more. Passionate about sharing knowledge, I've led coding workshops and tutored English, demonstrating my commitment to continuous learning and community engagement.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def generate_elevator_pitch(resume_text, api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an AI assistant that creates concise and impactful elevator pitches based on resume information. The elevator pitch should be no more than 1 minute long when spoken, highlighting the candidate's key strengths, experiences, and unique value proposition.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Based on the following resume, create an elevator pitch for him/her, write in 1st person tone:\\n\\n{resume_text}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        elevator_pitch = response.choices[0].message.content.strip()\n",
    "        return elevator_pitch\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error generating elevator pitch: {str(e)}\"\n",
    "\n",
    "\n",
    "resume_text = text\n",
    "\n",
    "# Generate the elevator pitch\n",
    "try:\n",
    "    elevator_pitch = generate_elevator_pitch(resume_text, api_key)\n",
    "\n",
    "    # Store the elevator pitch in MongoDB (assuming you have a MongoDB connection set up)\n",
    "    resumes_collection.update_one(\n",
    "        {'_id': latest_resume['_id']},\n",
    "        {\n",
    "            '$set': {\n",
    "                'elevator_pitch': elevator_pitch,\n",
    "                'pitch_generated_at': datetime.now(timezone.utc)\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Elevator pitch generated and stored successfully:\")\n",
    "    print(elevator_pitch)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:39.157903Z",
     "iopub.status.busy": "2025-02-03T17:55:39.157507Z",
     "iopub.status.idle": "2025-02-03T17:55:39.164449Z",
     "shell.execute_reply": "2025-02-03T17:55:39.163891Z"
    }
   },
   "outputs": [],
   "source": [
    "star_text='''Pre-Interview Preparation: What Every Job Seeker And New Graduate Should Do Before The First Phone Screen Or Interview\n",
    "Before you even get on a phone call or step into an interview room, proper preparation is key to ensuring you make a strong impres-sion. Taking the time to prepare not only helps you feel more confi-dent, but it also shows potential employers that you are serious about the opportunity.\n",
    "Research the Company Thoroughly\n",
    "Before any interaction with the hiring team, it's critical to research the company. A lack of knowledge about the employer can hurt your chances, as it suggests you’re uninterested or unprepared. Here’s what you need to focus on:\n",
    "• Company Overview: Familiarize yourself with the company’s mission, values, and culture. Check their website, social media channels, and any news articles to stay informed about recent developments.\n",
    "• Industry: Understand the company’s position in its industry and its competitors. You don’t need to be an expert, but having general knowledge shows you’re serious about the opportunity.\n",
    "• Key Players: Look up the leadership team, especially anyone who might be interviewing you. Knowing who you’ll be speaking with can give you an edge and help you tailor your questions or conversation.\n",
    "Study the Job Description in Detail\n",
    "A well-prepared candidate knows the job description inside and out. Break down the requirements and make sure you understand what’s expected of the role. Match your skills, experience, and achievements to the key qualifications they are looking for.\n",
    "• Identify your strengths: Highlight areas where your skills perfectly align with the job description.\n",
    "• Prepare to address any gaps: If you don’t meet 100% of the qualifications, be ready to discuss how your other skills or your ability to learn quickly can bridge those gaps.\n",
    "Prepare Your Key Talking Points\n",
    "You’ll want to walk into the interview ready to discuss your background, but it’s important to focus on what’s relevant to the position. Here’s how to prepare:\n",
    "• Craft your elevator pitch: Prepare a concise summary of who you are, your professional background, and what you bring to the role.\n",
    "• Frame your experience: Think about 3-5 accomplishments or projects that best demonstrate your abilities and tie them directly to the job you’re applying for.\n",
    "LEVELLING UP YOUR INTERVIEW GAME:\n",
    "BECOMING A STAR\n",
    "15\n",
    "Pre-Interview Preparation: What Every Job Seeker And New Graduate Should Do Before The First Phone Screen Or Interview Cont...\n",
    "Prepare Thoughtful Questions\n",
    "Hiring managers are evaluating you, but you should also be evaluating the company. Prepare questions that not only demonstrate your interest in the role but also help you gauge whether the company is the right fit for you. Examples include:\n",
    "“What are the key goals for someone in this role in the first 6-12 months?”\n",
    "“Can you tell me about the company culture and team dynamics?”\n",
    "“What does success look like in this position?”\n",
    "Asking thoughtful questions can show your genuine interest in the role, while also giving you deeper in-sight into the position and the company.\n",
    "Test Your Technology for Virtual Interviews\n",
    "If your interview is going to be virtual or over the phone, don’t wait until the last minute to check your equipment. Technical issues can quickly derail a great conversation and leave a poor impression.\n",
    "• Test your internet connection: Make sure it’s stable and reliable.\n",
    "• Test your camera and microphone: For video interviews, ensure the camera is positioned well, with good lighting, and that your microphone is clear.\n",
    "• Find a quiet space: Minimize background noise, and ensure that your surroundings are professional and free from distractions.\n",
    "Review Your Resume and LinkedIn Profile\n",
    "Make sure your resume is up-to-date and consistent with what’s on your LinkedIn profile. Hiring managers often check both. Be prepared to talk through any gaps in employment, transitions between jobs, or spe-cific projects you’ve highlighted. Also, make sure your LinkedIn profile is polished and reflects the same key points as your resume.\n",
    "Practice Mock Interviews\n",
    "Whether it’s with a friend, mentor, or even in front of a mirror, mock interviews help you polish your re-sponses and get comfortable speaking about your experience. Focus on:\n",
    "• Clear, concise answers: Don’t ramble or go off-topic.\n",
    "• Body language: Make sure to maintain eye contact, sit up straight, and use appropriate gestures.\n",
    "• Pacing and tone: Avoid speaking too fast or too slowly. Practice maintaining an upbeat, confident tone.\n",
    "Know Your Availability and Salary Expectations\n",
    "Be prepared to discuss your availability for the role, including your potential start date. If salary is likely to come up, have a range ready based on your research of the market and your level of experience. Sites like Glassdoor and PayScale can help you find industry-standard salaries for similar positions.\n",
    "Get a Good Night’s Sleep\n",
    "It might seem obvious, but getting enough sleep the night before is essential for being at your best. A well-rested mind will help you stay calm, focused, and responsive during your interview.\n",
    "16\n",
    "Dress For Success - Interview Attire and Etiquette\n",
    "When it comes to interviews, both in-person and virtual, the way you present yourself can make a lasting impression. Whether you're a seasoned professional or a fresh graduate, dressing and be-having appropriately plays a crucial role in shaping how employers perceive you.\n",
    "In-Person Interviews:\n",
    "• Understand the Company Culture: Research the company's dress code beforehand. If it's a cor-porate or conservative environment, opt for formal attire (e.g., suits or professional dresses). For more relaxed workplaces, business casual is acceptable, but it's better to be slightly overdressed than underdressed.\n",
    "• Invest in Fit and Quality: Your clothing should be clean, well-fitted, and wrinkle-free. Ill-fitting clothes can be distracting and suggest a lack of attention to detail. Polish your shoes and avoid flashy or excessive accessories.\n",
    "• Neutral and Professional Colors: Stick to neutral colors like navy, black, gray, or white. These con-vey professionalism and are less likely to distract the interviewer from your qualifications and skills.\n",
    "• Grooming Matters: Personal hygiene is paramount. Make sure your hair is neat, your nails are clean, and your breath is fresh. Avoid overpowering colognes or perfumes, as these can be dis-tracting or bothersome in a small room.\n",
    "Online Interviews:\n",
    "• Professional from the Waist Up: Even if you're behind a screen, dress as if you’re meeting in per-son. At the very least, wear a button-up shirt, blouse, or blazer. Avoid the temptation to wear sweatpants or pajamas below the camera line—you never know when you'll need to stand up!\n",
    "• Choose a Simple Background: Your interview setting should be distraction-free. A plain wall or a tidy space will keep the focus on you, not your surroundings. Ensure proper lighting, and sit facing a window or a light source for a clear, bright appearance.\n",
    "• Test Technology in Advance: Dress rehearsal isn't just for actors—test your equipment (camera, mic, internet) before the interview to avoid any last-minute hiccups. It shows you're prepared and serious about the opportunity.\n",
    "17\n",
    "How To Highlight Soft Skills in An Interview\n",
    "The interview is the time to show off those soft skills in action. Here’s how you can subtly weave them in-to your answers:\n",
    "Use the STAR Method to Show Problem-Solving & Teamwork\n",
    "The STAR method (Situation, Task, Action, Result) is perfect for soft skills questions. It gives you a struc-ture for storytelling that really highlights how you’ve used your skills in real life.\n",
    "Example Question: “Tell me about a time you worked in a team.”\n",
    "Answer using STAR:\n",
    "• Situation: “At my internship, we had to work on a project with a tight deadline.”\n",
    "• Task: “I was responsible for coordinating between the marketing and sales teams to ensure every-one was on the same page.”\n",
    "• Action: “I set up weekly meetings and clear communication channels to keep everyone aligned.”\n",
    "Result: “We finished the project ahead of schedule, and our cross-team collaboration increased by 25%.”\n",
    "This shows teamwork, communication, and time management—all in one story! Plus, it paints you as a capable team player with real results.\n",
    "When They Ask About Strengths, Highlight Soft Skills\n",
    "When the interviewer says, “Tell me about your strengths,” it’s your time to shine. Don’t just say you’re a “good communicator”—talk about how you communicate well.\n",
    "Example Answer: “I think one of my biggest strengths is my ability to communicate with people from different backgrounds. For example, at my last job, I regularly had to explain technical information to non-technical team members, and I got really good at simplifying complex concepts so everyone understood.”\n",
    "This way, you’re proving the strength instead of just saying it.\n",
    "Answer Behavioral Questions with Soft Skills in Mind\n",
    "Behavioral questions are designed to find out how you’ll handle situations at work. Always answer these with soft skills at the forefront.\n",
    "Example Behavioral Question: “How do you handle stress or tight deadlines?”\n",
    "Answer: “I prioritize tasks and focus on what’s most urgent first. For example, during finals week at school, I had to juggle multiple assignments. I broke them down into smaller steps and communicated with my professors about expectations. By staying organized and calm, I was able to meet all my dead-lines without sacrificing quality.”\n",
    "You’ve just demonstrated adaptability, time management, and communication in one answer.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T17:55:39.166537Z",
     "iopub.status.busy": "2025-02-03T17:55:39.166157Z",
     "iopub.status.idle": "2025-02-03T17:55:41.904337Z",
     "shell.execute_reply": "2025-02-03T17:55:41.903742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR INFO generated and stored successfully:\n",
      "**Situation:** Developed a system where users can upload their resumes for analysis using OpenAI's API and Langchain.\n",
      "**Task:** Implement API-driven processes for real-time feedback and quantitative assessment of resumes.\n",
      "**Action:** Utilized Python, JavaScript, MongoDB, and OpenAI API to efficiently analyze and evaluate resumes.\n",
      "**Result:** Successfully leveraged MongoDB to manage and store user data, analysis results, and feedback history, enhancing the efficiency of resume evaluation processes.\n",
      "\n",
      "**Situation:** Designed and implemented a comprehensive data pipeline to analyze customer purchase behavior.\n",
      "**Task:** Integrate multiple data sources and utilize Python for data cleaning and processing.\n",
      "**Action:** Developed an SQL database for efficient storage and retrieval of customer information and purchase patterns.\n",
      "**Result:** Created automated dashboards using Python libraries and Tableau to visualize sales trends and key performance metrics, enabling data-driven decision-making for marketing strategies.\n",
      "\n",
      "**Situation:** Cleaned and visualized key dataset features to identify tipping patterns in a restaurant tips prediction project.\n",
      "**Task:** Evaluate model performance using metrics like mean absolute error, root mean squared error, and R-squared.\n",
      "**Action:** Utilized Python, Machine Learning, Pandas, Matplotlib, and Scikit-Learn to analyze and draw insights from tipping patterns.\n",
      "**Result:** Provided actionable insights for restaurant customer behavior based on model performance metrics and data visualization.\n"
     ]
    }
   ],
   "source": [
    "def generate_star(star_text, text):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f'''Fetch information about STAR method, This is some star information:\\n\\n {star_text} \\n\\n You are a STAR (Situation, Task, Action, Result) master. You give star information by reviewing their resume. Give result without any starting or ending statements, just in different points. Also dont add any \"-\" in between. Format the output so that the words **Situation**, **Task**, **Action**, and **Result** are bold using markdown syntax .'''\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"This is the resume text:\\n\\n {text} \\n\\n analyse it and identify specific situations, tasks, actions, and results from it that can be used during an interview. Clearly label each STAR component and provide 3 STAR examples:\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7                                                                   \n",
    "        )\n",
    "\n",
    "        star_info = response.choices[0].message.content.strip()\n",
    "        return star_info\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error generating elevator pitch: {str(e)}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    star_info = generate_star(star_text, text)\n",
    "\n",
    "    # Store the elevator pitch in MongoDB (assuming you have a MongoDB connection set up)\n",
    "    resumes_collection.update_one(\n",
    "        {'_id': latest_resume['_id']},\n",
    "        {\n",
    "            '$set': {\n",
    "                'star_info': star_info,\n",
    "                'star_generated_at': datetime.now(timezone.utc)\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"STAR INFO generated and stored successfully:\")\n",
    "    print(star_info)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
